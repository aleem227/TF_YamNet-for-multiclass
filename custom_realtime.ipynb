{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Finished recording.\n",
      "Predicted class: Computer_keyboard\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "\n",
    "\n",
    "def compute_mfcc(y, sr):\n",
    "    # Check if audio length is greater than or equal to 10 seconds\n",
    "    if len(y) >= sr * 10:\n",
    "        # Clip the audio to 10 seconds\n",
    "        y = y[:sr * 10]\n",
    "    else:\n",
    "        # If audio length is less than 10 seconds, zero-pad at the end\n",
    "        zero_padding = np.zeros(sr * 10 - len(y), dtype=np.float32)\n",
    "        y = np.concatenate([y, zero_padding])\n",
    "        \n",
    "    # Extract MFCC features for the entire audio\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "    \n",
    "    return mfccs.T  # Transpose the MFCC matrix to have time along the rows and features along the columns\n",
    "\n",
    "\n",
    "# Define parameters for audio recording\n",
    "RATE = 16000\n",
    "DURATION = 10  # Record for 10 seconds\n",
    "\n",
    "# Record audio for 10 seconds\n",
    "print(\"Recording...\")\n",
    "audio_data = sd.rec(int(DURATION * RATE), samplerate=RATE, channels=1, dtype=np.float32)\n",
    "sd.wait()\n",
    "print(\"Finished recording.\")\n",
    "\n",
    "# Preprocess the recorded audio\n",
    "y = audio_data[:, 0]  # Extract mono audio data\n",
    "sr = RATE\n",
    "mfcc = compute_mfcc(y, sr)\n",
    "\n",
    "# Reshape the MFCC array to match the input shape expected by the TFLite model\n",
    "mfcc_input = mfcc.reshape(1, mfcc.shape[0], mfcc.shape[1])\n",
    "\n",
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"custom_LSTM_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Set input tensor\n",
    "interpreter.set_tensor(input_details[0]['index'], mfcc_input)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the output tensor\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "# Get the predicted class ID\n",
    "predicted_class_id = np.argmax(output_data)\n",
    "\n",
    "# Define class mapping\n",
    "class_mapping = {\n",
    "    0: 'Clicking',\n",
    "    1: 'Computer_keyboard',\n",
    "    2: 'Cough',\n",
    "    3: 'Female_speech,_woman_speaking',\n",
    "    4: 'Hair_dryer',\n",
    "    5: 'Laughter',\n",
    "    6: 'Male_speech,_man_speaking',\n",
    "    7: 'Silence',\n",
    "    8: 'Sneeze',\n",
    "    9: 'Vacuum_cleaner',\n",
    "    10: 'book_page_flip'\n",
    "}\n",
    "\n",
    "# Map the predicted class ID to its label\n",
    "predicted_class_label = class_mapping[predicted_class_id]\n",
    "\n",
    "print(\"Predicted class:\", predicted_class_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording and processing in real-time. Press Ctrl+C to stop...\n",
      "Gathering initial audio...\n",
      "Gathering initial audio...\n",
      "Gathering initial audio...\n",
      "Gathering initial audio...\n",
      "Gathering initial audio...\n",
      "Gathering initial audio...\n",
      "Gathering initial audio...\n",
      "Gathering initial audio...\n",
      "Gathering initial audio...\n",
      "Gathering initial audio...\n",
      "Initial Predicted class: Computer_keyboard\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Computer_keyboard\n",
      "Predicted class: Computer_keyboard\n",
      "Predicted class: Computer_keyboard\n",
      "Predicted class: Computer_keyboard\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Male_speech,_man_speaking\n",
      "Predicted class: Cough\n",
      "Predicted class: Male_speech,_man_speaking\n",
      "Predicted class: Male_speech,_man_speaking\n",
      "Predicted class: Cough\n",
      "Predicted class: Male_speech,_man_speaking\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Cough\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Male_speech,_man_speaking\n",
      "Predicted class: Computer_keyboard\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Male_speech,_man_speaking\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Computer_keyboard\n",
      "Predicted class: Computer_keyboard\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Computer_keyboard\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Female_speech,_woman_speaking\n",
      "Predicted class: Female_speech,_woman_speaking\n",
      "Predicted class: Computer_keyboard\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Computer_keyboard\n",
      "Predicted class: Computer_keyboard\n",
      "Predicted class: Female_speech,_woman_speaking\n",
      "Predicted class: Female_speech,_woman_speaking\n",
      "Predicted class: Female_speech,_woman_speaking\n",
      "Predicted class: Cough\n",
      "Predicted class: Female_speech,_woman_speaking\n",
      "Predicted class: Female_speech,_woman_speaking\n",
      "Predicted class: Female_speech,_woman_speaking\n",
      "Predicted class: Female_speech,_woman_speaking\n",
      "Predicted class: Computer_keyboard\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Female_speech,_woman_speaking\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Female_speech,_woman_speaking\n",
      "Predicted class: Female_speech,_woman_speaking\n",
      "Predicted class: Female_speech,_woman_speaking\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Female_speech,_woman_speaking\n",
      "Predicted class: Male_speech,_man_speaking\n",
      "Predicted class: Female_speech,_woman_speaking\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Male_speech,_man_speaking\n",
      "Predicted class: Male_speech,_man_speaking\n",
      "Predicted class: Male_speech,_man_speaking\n",
      "Predicted class: Male_speech,_man_speaking\n",
      "Predicted class: Male_speech,_man_speaking\n",
      "Predicted class: Male_speech,_man_speaking\n",
      "Predicted class: Male_speech,_man_speaking\n",
      "Predicted class: Computer_keyboard\n",
      "Predicted class: Computer_keyboard\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Male_speech,_man_speaking\n",
      "Predicted class: Computer_keyboard\n",
      "Predicted class: Computer_keyboard\n",
      "Predicted class: Computer_keyboard\n",
      "Predicted class: Computer_keyboard\n",
      "Predicted class: Male_speech,_man_speaking\n",
      "Predicted class: Computer_keyboard\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Computer_keyboard\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Vacuum_cleaner\n",
      "Predicted class: Female_speech,_woman_speaking\n",
      "Predicted class: Female_speech,_woman_speaking\n",
      "Predicted class: Female_speech,_woman_speaking\n",
      "Predicted class: Female_speech,_woman_speaking\n",
      "Predicted class: Female_speech,_woman_speaking\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 82\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Now, keep processing in real-time\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# Wait for 1 second worth of new data\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSEGMENT_DURATION\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;66;03m# Perform inference\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     predicted_class_id \u001b[38;5;241m=\u001b[39m inference_from_buffer(audio_buffer, RATE)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "from collections import deque\n",
    "import time\n",
    "\n",
    "def compute_mfcc(y, sr):\n",
    "    # Extract MFCC features for the entire audio\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "    return mfccs.T  # Transpose the MFCC matrix\n",
    "\n",
    "# Define parameters for audio recording\n",
    "RATE = 16000\n",
    "SEGMENT_DURATION = 1  # Duration of each audio segment in seconds\n",
    "TOTAL_DURATION = 10  # Total duration of audio to maintain in the buffer, in seconds\n",
    "SEGMENT_SAMPLES = RATE * SEGMENT_DURATION  # Number of samples in each segment\n",
    "BUFFER_SAMPLES = RATE * TOTAL_DURATION  # Total number of samples in the buffer\n",
    "\n",
    "# Initialize a deque as a ring buffer to store audio data\n",
    "audio_buffer = deque(maxlen=BUFFER_SAMPLES)\n",
    "\n",
    "# Initialize the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"custom_LSTM_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "def inference_from_buffer(buffer, rate):\n",
    "    # Convert the buffer to a numpy array\n",
    "    audio_data = np.array(buffer)\n",
    "    # Compute MFCC\n",
    "    mfcc = compute_mfcc(audio_data, rate)\n",
    "    # Reshape the MFCC for the model\n",
    "    mfcc_input = mfcc.reshape(1, mfcc.shape[0], mfcc.shape[1])\n",
    "    # Set input tensor\n",
    "    interpreter.set_tensor(input_details[0]['index'], mfcc_input)\n",
    "    # Run inference\n",
    "    interpreter.invoke()\n",
    "    # Get the output tensor\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    # Get the predicted class ID\n",
    "    return np.argmax(output_data)\n",
    "\n",
    "class_mapping = {\n",
    "    0: 'Clicking',\n",
    "    1: 'Computer_keyboard',\n",
    "    2: 'Cough',\n",
    "    3: 'Female_speech,_woman_speaking',\n",
    "    4: 'Hair_dryer',\n",
    "    5: 'Laughter',\n",
    "    6: 'Male_speech,_man_speaking',\n",
    "    7: 'Silence',\n",
    "    8: 'Sneeze',\n",
    "    9: 'Vacuum_cleaner',\n",
    "    10: 'book_page_flip'\n",
    "}\n",
    "    \n",
    "\n",
    "# Callback function to process each block of audio\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    # Flatten and append new audio data to the buffer\n",
    "    audio_buffer.extend(indata[:, 0])\n",
    "\n",
    "# Start recording and processing\n",
    "print(\"Recording and processing in real-time. Press Ctrl+C to stop...\")\n",
    "with sd.InputStream(samplerate=RATE, channels=1, dtype=np.float32, callback=audio_callback):\n",
    "    # Zero-pad the initial buffer if necessary\n",
    "    while len(audio_buffer) < BUFFER_SAMPLES:\n",
    "        time.sleep(SEGMENT_DURATION)\n",
    "        print(\"Gathering initial audio...\")\n",
    "\n",
    "    # Perform the first inference\n",
    "    predicted_class_id = inference_from_buffer(audio_buffer, RATE)\n",
    "    print(\"Initial Predicted class:\", class_mapping[predicted_class_id])\n",
    "\n",
    "    # Now, keep processing in real-time\n",
    "    while True:\n",
    "        # Wait for 1 second worth of new data\n",
    "        time.sleep(SEGMENT_DURATION)\n",
    "        # Perform inference\n",
    "        predicted_class_id = inference_from_buffer(audio_buffer, RATE)\n",
    "        print(\"Predicted class:\", class_mapping[predicted_class_id])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
